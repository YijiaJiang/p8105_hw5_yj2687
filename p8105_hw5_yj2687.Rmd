---
title: "p8105_hw5_yj2687"
author: "Yijia Jiang"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "right"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```



## Problem 1 (Longitudinal study)

```{r, warning=FALSE, message=FALSE}
# Import the dataset
full_df = 
  tibble(
    files = list.files("./p8105_hw5_data/"),
    path = str_c("./p8105_hw5_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```


```{r, warning=FALSE, message=FALSE}
# Tidy the data
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```



```{r, warning=FALSE, message=FALSE}
# Make a spaghetti plot showing observations on each subject over time
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group) + 
  labs(x = "Week", y = "Outcome", 
       title = "Observations on Each Subject over 8 Weeks in Two Groups")
```

* The plot indicates high within-subject correlation -- subjects who start above average end up above average, and those that start below average end up below average. Subjects in the control group generally don't change over time, but those in the experiment group increase their outcome in a roughly linear way. 

&nbsp;



## Problem 2 (Homicide Dataset)
```{r, warning = FALSE, message=FALSE}
# Import dataset
homicide_raw <- read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

* The raw data collected by Washington Post reports a total of `r homicide_raw %>% nrow()` criminal homicides over the past decade in 50 of the largest American cities, including `r homicide_raw %>% ncol()` variables, namely `r homicide_raw %>% names`.
* The reported date, longitude and latitude are designated as numeric variables, and the remaining 9 variables including age, are defined as characters. 
* We can observe some entries for the victim's race, age, and sex are reported as unknown.
* There exist `r sum(is.na(homicide_raw$lat))` missing values in `lat`, `r sum(is.na(homicide_raw$lon))` in `lon`, accounting for `r sum(is.na(homicide_raw$lat)/nrow(homicide_raw)) %>% scales::percent(0.01)`, `r sum(is.na(homicide_raw$lon)/nrow(homicide_raw)) %>% scales::percent(0.01)`, respectively. 
* In particular, there was one record from the city of `Tulsa`, which is located in the state of `OK`, was incorrectly logged as being in the state of `AL`, which will be removed as a typo.


```{r, warning = FALSE, message=FALSE}
# Clean dataset and create variables city_state, resolved
homicide_df = homicide_raw %>% 
  janitor::clean_names() %>%
  mutate(reported_date = as.Date(as.character(reported_date), format = "%Y%m%d")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved",
    )) %>% 
  relocate(city_state) %>%
  filter(city_state != "Tulsa, AL")
```


```{r, warning = FALSE, message=FALSE}
# Summarize within cities to calculate the total number of homicides and unsolved homicides
summary_hom_df = homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )

summary_hom_df %>% 
  knitr::kable(align = "lrr", 
               col.names = c("City", "Total number of homicides", "Number of unsovled homicides"))
```


```{r, warning = FALSE, message=FALSE}
# Estimate the proportion of unsolved homicides in Baltimore, MD
prop_baltimore = prop.test(
  summary_hom_df %>% filter(city_state == "Baltimore, MD") %>% pull(hom_unsolved), 
  summary_hom_df %>% filter(city_state == "Baltimore, MD") %>% pull(hom_total)) 

prop_baltimore %>% broom::tidy()
```


```{r, warning = FALSE, message=FALSE}
# Iterate to estimate the proportion of unsolved homicides in all cities
prop_cities = 
  summary_hom_df %>% 
  mutate(
    prop_tests = purrr::map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = purrr::map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```



```{r, warning = FALSE, message=FALSE}
# Create a plot showing the estimates and CIs for each city
prop_cities %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(
    title = "Estimates and 95% CIs of Proportion of Unsolved Homicides in All Cities",
    x = "City",
    y = "Estimate")
```



&nbsp;



## Problem 3 (Simulation to Explore Power)
```{r, warning = FALSE, message=FALSE}
# Construct function for one-sample t-test
ttest = function(n = 30, mu, sigma = 5){
  sim_data = tibble(x = rnorm(n, mean = mu, sd = sigma)) 
    
  test_data = t.test(sim_data, mu = 0, conf.level = 0.95)
  
  sim_data %>% 
    summarize(
      estimate = pull(broom::tidy(test_data), estimate),
      p_value = pull(broom::tidy(test_data), p.value)
    )
}

# Generate 5000 datasets from the model and repeat the t-test for mu = 0,1,2,3,4,5,6
set.seed(1234)

sim_result = 
  tibble(mu = c(0:6)) %>% 
  mutate(
    output_list = map(.x = mu, ~rerun(5000, ttest(mu = .x))),
    estimate_df = map(output_list, bind_rows)
    ) %>% 
  select(-output_list) %>% 
  unnest(estimate_df)
```



```{r, warning = FALSE, message=FALSE}
# Make a plot showing the proportion of times the null was rejected on the y axis and the true value of mu on the x axis
sim_result  %>% 
  group_by(mu) %>%
  filter(p_value < 0.05) %>% 
  summarize(rej_num = n(), rej_prop = rej_num/5000) %>% 
  ggplot(aes(x = mu, y = rej_prop)) + 
  geom_point(alpha = 0.8) +
  geom_line(alpha = 0.8) +
  geom_text(aes(label = round(rej_prop, 3)), vjust = -1, size = 3) + 
  scale_x_continuous(limits = c(0,6), breaks = seq(0,6,1)) +
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.2)) +
  labs(
    title = "Association between effect size and power of the t-test",
    x = "True mean",
    y = "Proportion of times the null was rejected")
```

* With the true mean increases and goes away from 0, the proportion of times that the null hypothesis was rejected increases as well, approaching to 1. When the difference between true mean and the null is large enough, the growth rate of proportion slows down, getting closer to 1. The larger the effect size, the greater the power, that is, the power of the test is positively correlated with the effect size. 



```{r, warning=FALSE, message=FALSE}
# Make a plot showing the average estimate of mu on the y axis and the true value of mu on the x axis
sim_result %>% 
  group_by(mu) %>% 
  summarise(avg_estimate = mean(estimate)) %>% 
  ggplot(aes(x = mu, y = avg_estimate)) +
  geom_point(alpha = 0.8) +
  geom_line(alpha = 0.8) +
  geom_text(aes(label = round(avg_estimate,2)), vjust = -1, size = 3) + 
  scale_x_continuous(limits = c(0,6.5), breaks = seq(0,6,1)) +
  scale_y_continuous(limits = c(-0.1,6.5), breaks = seq(0,6,1)) +
  labs(
    title = "Association between average estimates and true mean",
    x = "True mean",
    y = "Average estimate mean"
  ) 


# Make a second plot (or overlay on the first) the average estimate of mu only in samples for which the null was rejected on the y axis and the true value of mu on the x axis
sim_rej = sim_result %>% 
  filter(p_value < 0.05) %>% 
  group_by(mu) %>% 
  summarise(avg_estimate = mean(estimate)) 

sim_result %>% 
  group_by(mu) %>% 
  summarise(avg_estimate = mean(estimate)) %>% 
  ggplot(aes(x = mu, y = avg_estimate, color = "Total samples")) +
  geom_point() +
  geom_line() + 
  geom_text(aes(label = round(avg_estimate,2)), vjust = 2, size = 3) + 
  geom_point(data = sim_rej, aes(color = "Rejected samples")) +
  geom_line(data = sim_rej, aes(x = mu, y = avg_estimate, color = "Rejected samples")) + 
  geom_text(data = sim_rej, aes(label = round(avg_estimate,2), color = "Rejected samples"), vjust = -1, size = 3) + 
  scale_x_continuous(limits = c(0,6.5), breaks = seq(0,6,1)) +
  scale_y_continuous(limits = c(-0.5,6.5), breaks = seq(0,6,1)) +
  labs(x = "True mean",
       y = "Average estimate mean",
       title = "Association between average estimates and true mean",
       color = "Type") +
  scale_color_manual(values = c("Total samples" = "#4393C3", "Rejected samples" = "#D6604D"))
```


* For the total samples, the average estimate means are approximately equal to the true means.
* However, for the rejected samples, when the $\mu$ is equal to 0, 1, 2 and 3, the sample average of $\hat{\mu}$ across tests for which the null is rejected is different from the true value of $\mu$. When $\mu$ is equal to 4, 5 and 6, the rejected average estimates are close to the true mean of $\mu$.
* This is because the probability that the null hypothesis is rejected increases with effect size increases. When we simulate samples with higher true means, we obtain a larger detectable effect size, which allows us to reject the null hypothesis more correctly. This again, has to do with the statistical power.



